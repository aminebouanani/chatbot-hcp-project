import os
import json
import numpy as np
import google.generativeai as genai
import faiss
from flask import Flask, request, jsonify
from flask_cors import CORS
from sentence_transformers import SentenceTransformer
from deep_translator import GoogleTranslator
# MODIFICATION : Importation de la nouvelle biblioth√®que de d√©tection de langue
from langdetect import detect

# --- 1. Configuration et Chargement des Mod√®les et Donn√©es ---

print("üöÄ D√©marrage du serveur backend du chatbot (Mode Complet)...")

# Configuration de l'API Google Gemini
try:
    GOOGLE_API_KEY = "AIzaSyC_SP-vD9LQn69CN-PjLH0Vz4DlnSbc7Hw"  # Votre cl√© API
    genai.configure(api_key=GOOGLE_API_KEY)
    gemini = genai.GenerativeModel("gemini-1.5-flash")
    print("‚úÖ Cl√© API Google configur√©e et mod√®le 'gemini-1.5-flash' pr√™t.")
except Exception as e:
    print(f"‚ùå ERREUR CRITIQUE lors de la configuration de Gemini : {e}")
    gemini = None

# Chargement des mod√®les et des traducteurs
try:
    print("‚è≥ Chargement des mod√®les de langue et de traduction...")
    model = SentenceTransformer("distiluse-base-multilingual-cased-v2")
    translator = GoogleTranslator(source="auto", target="fr")
    print("‚úÖ Mod√®les de langue charg√©s.")
except Exception as e:
    print(f"‚ùå ERREUR lors du chargement des mod√®les SentenceTransformer : {e}")

# Chargement des donn√©es pour la recherche hybride
try:
    print("‚è≥ Chargement des donn√©es structur√©es et non structur√©es...")
    with open("structured_stats.json", "r", encoding="utf-8") as f:
        structured_stats = json.load(f)
    structured_embeddings = np.load("structured_embeddings.npy")
    print("   -> Donn√©es statistiques charg√©es.")
    faiss_index = faiss.read_index("data_index.faiss")
    with open("data_metadata.json", "r", encoding="utf-8") as f:
        text_metadata = json.load(f)
    print("   -> Index Faiss et m√©tadonn√©es textuelles charg√©s.")
    print("‚úÖ Toutes les donn√©es ont √©t√© charg√©es avec succ√®s.")
except FileNotFoundError as e:
    print(f"‚ùå ERREUR CRITIQUE : Fichier de donn√©es manquant : {e}")
    structured_stats = []
    faiss_index = None


# --- 2. Fonctions de Recherche et de G√©n√©ration (Logique compl√®te) ---

def search_text(question, k=5):
    """
    Recherche dans les donn√©es textuelles non structur√©es √† l'aide de Faiss.
    """
    if not faiss_index: return []
    print("   -> Traduction et recherche dans l'index de texte Faiss...")
    # On conserve la traduction en fran√ßais car la base de connaissance est en fran√ßais
    question_fr = translator.translate(question)
    q_emb = model.encode([question_fr]).astype("float32")
    distances, indices = faiss_index.search(q_emb, k)
    retrieved = [text_metadata[idx]["text"] for idx in indices[0]]
    print(f"   -> {len(retrieved)} morceaux de texte pertinents trouv√©s via Faiss.")
    return retrieved


def search_structured_stats_fast(question, top_k=5):
    """
    Recherche dans les donn√©es statistiques structur√©es.
    """
    if not structured_stats: return []
    print("   -> Traduction et recherche dans les donn√©es statistiques structur√©es...")
    # On conserve la traduction en fran√ßais ici aussi
    question_fr = translator.translate(question)
    q_emb = model.encode([question_fr]).astype("float32")[0]
    sims = np.dot(structured_embeddings, q_emb) / (
                np.linalg.norm(structured_embeddings, axis=1) * np.linalg.norm(q_emb))
    top_indices = sims.argsort()[::-1][:top_k]
    retrieved = [structured_stats[i] for i in top_indices]
    print(f"   -> {len(retrieved)} lignes de donn√©es pertinentes trouv√©es.")
    return retrieved


# MODIFICATION : Remplacement de l'ancienne fonction de g√©n√©ration par la nouvelle fonction dynamique
def construire_prompt_dynamique(question, text_chunks, structured_rows, langue):
    """
    Construit le prompt pour le LLM en adaptant la langue des instructions.
    """
    # Formatage du contexte
    structured_context = "\n".join([
                                       f"- [{r.get('zone', 'N/A')} | {r.get('milieu', 'N/A')} | {r.get('sexe', 'N/A')}]: {r.get('indicator', 'N/A')} ‚Üí {r.get('value', 'N/A')}"
                                       for r in structured_rows])
    text_context = "\n\n".join(text_chunks)

    # Instructions communes
    instructions_base = """
    Tu es un assistant conversationnel intelligent, naturel et serviable.
    Ton r√¥le principal est d'aider les utilisateurs en te basant sur des donn√©es du Haut-Commissariat au Plan (HCP).
    - SOIS NATUREL : Comporte-toi comme un humain. Si la question est une salutation simple comme "Bonjour" ou "Salam", r√©ponds simplement.
    - SOIS DIRECT : Ne dis JAMAIS des phrases comme "Selon les documents fournis", "D'apr√®s le contexte", "Dans les informations que j'ai". R√©ponds directement √† la question.
    - SOIS HONN√äTE : Si les informations ci-dessous ne te permettent pas de r√©pondre, ou si elles sont vides, dis simplement que tu ne sais pas, de mani√®re naturelle. Ne cherche pas dans tes connaissances g√©n√©rales, sauf pour les salutations.
    """

    # Instructions sp√©cifiques √† la langue
    if langue == 'fr':
        instructions_langue = """
        - R√âPONDS EN FRAN√áAIS : La question est en fran√ßais, ta r√©ponse doit √™tre en fran√ßais clair et naturel.
        - EXEMPLE DE REFUS : Si tu ne sais pas, dis quelque chose comme "Je n'ai pas d'information pr√©cise √† ce sujet." ou "Je ne saurais pas vous dire.".
        """
        question_label = "Question de l'utilisateur"
        reponse_label = "Ta r√©ponse (en fran√ßais) :"
    else:  # Par d√©faut, on consid√®re que c'est de la Darija (langue 'ar' ou autre)
        instructions_langue = """
        - R√âPONDS EN DARIJA : La question est en Darija, ta r√©ponse doit √™tre en Darija marocaine claire et naturelle.
        - EXEMPLE DE REFUS : Si tu ne sais pas, dis quelque chose comme "ŸÖÿß ÿπŸÜÿØŸäÿ¥ ÿ¥Ÿä ŸÖÿπŸÑŸàŸÖÿ© ŸÖÿ∂ÿ®Ÿàÿ∑ÿ© ÿπŸÑŸâ ŸáÿßÿØ ÿßŸÑŸÖŸàÿ∂Ÿàÿπ." ou "ŸÖÿß ŸÜŸÇÿØÿ±ÿ¥ ŸÜÿ¨ÿßŸàÿ®ŸÉ ÿπŸÑŸâ ŸáÿßÿØŸä.".
        """
        question_label = "ÿßŸÑÿ≥ÿ§ÿßŸÑ ÿØŸäÿßŸÑ ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ"
        reponse_label = "ÿßŸÑÿ¨Ÿàÿßÿ® ÿØŸäÿßŸÑŸÉ (ÿ®ÿßŸÑÿØÿßÿ±ÿ¨ÿ© ÿßŸÑŸÖÿ∫ÿ±ÿ®Ÿäÿ©) :"

    # Assemblage final du prompt
    prompt_final = f"""
{instructions_base}
{instructions_langue}

---
CONTEXTE FOURNI (√† utiliser si pertinent)
Contexte textuel (analyses g√©n√©rales) :
{text_context}

Contexte statistique (chiffres pr√©cis) :
{structured_context}
---

{question_label}:
{question}

{reponse_label}
"""
    print("\n--- PROMPT DYNAMIQUE ENVOY√â √Ä L'API GEMINI ---")
    print(prompt_final)
    print("-------------------------------------------------------\n")

    if not gemini:
        return "Service d'IA non configur√©."

    try:
        print("   -> Envoi de la requ√™te √† l'API Gemini...")
        response = gemini.generate_content(prompt_final)
        print("   -> R√©ponse re√ßue de l'API.")
        return response.text
    except Exception as e:
        print(f"‚ùå ERREUR lors de l'appel √† l'API Gemini : {e}")
        return "D√©sol√©, une erreur technique est survenue lors de la communication avec l'IA."


# --- 3. API Flask ---

app = Flask(__name__)
CORS(app)


@app.route('/ask', methods=['POST'])
def ask_chatbot_api():
    if not request.json or 'question' not in request.json:
        return jsonify({'error': 'Requ√™te invalide, "question" manquante.'}), 400

    question = request.json['question']
    print(f"\n\n=============================================")
    print(f"‚ùì Question re√ßue : {question}")

    # MODIFICATION : D√©tection de la langue de la question
    try:
        langue_detectee = detect(question)
        print(f"   -> Langue d√©tect√©e : '{langue_detectee}'")
    except Exception as e:
        print(f"   -> Avertissement : √âchec de la d√©tection de langue ({e}). Utilisation du fran√ßais par d√©faut.")
        langue_detectee = 'fr'

    # Pipeline de recherche hybride (cette partie ne change pas)
    text_chunks = search_text(question)
    structured_rows = search_structured_stats_fast(question)

    # MODIFICATION : Appel de la nouvelle fonction de g√©n√©ration de r√©ponse
    answer = construire_prompt_dynamique(question, text_chunks, structured_rows, langue_detectee)

    print(f"ü§ñ R√©ponse finale g√©n√©r√©e : {answer}")
    return jsonify({'answer': answer})


@app.route('/', methods=['GET'])
def health_check():
    return "‚úÖ Le serveur backend du chatbot (Mode Complet Hybride) est en marche."


# --- 4. Lancement du Serveur ---

if __name__ == '__main__':
    # MODIFICATION : Ajout de use_reloader=False pour la stabilit√© pendant le d√©veloppement
    app.run(host='0.0.0.0', port=5000, debug=True, use_reloader=False)  